{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimum.intel.openvino import OVModelForVisualCausalLM\n",
    "from transformers import AutoProcessor, TextStreamer\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ov_model_path = \"ov-Qwen2.5-VL-3B-Instruct-INT4\"\n",
    "device=\"CPU\"\n",
    "min_pixels = 256 * 28 * 28\n",
    "max_pixels = 1280 * 28 * 28\n",
    "image_path = \"demo.jpeg\"\n",
    "\n",
    "model = OVModelForVisualCausalLM.from_pretrained(ov_model_path, device=device)\n",
    "processor = AutoProcessor.from_pretrained(ov_model_path, min_pixels=min_pixels, max_pixels=max_pixels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(image_path)\n",
    "question = \"Describe this image.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": f\"file://{image_path}\",\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": question},\n",
    "        ],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "image_inputs, video_inputs = process_vision_info(messages)\n",
    "inputs = processor(text=[text], images=image_inputs, videos=video_inputs, padding=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(image)\n",
    "print(\"Question:\")\n",
    "print(question)\n",
    "print(\"Answer:\")\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=100, streamer=TextStreamer(processor.tokenizer, skip_prompt=True, skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradio_helper import make_demo\n",
    "# demo = make_demo(model, processor)\n",
    "demo = make_demo(model)\n",
    "try:\n",
    "    demo.launch(debug=True)\n",
    "except Exception:\n",
    "    demo.launch(debug=True, share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ov-multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
